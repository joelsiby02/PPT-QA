{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf5d16-4464-4e15-a620-02a49944f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"unstructured[all-docs]\"\n",
    "!pip install libmagic-dev poppler-utils tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "879af281-24d2-4720-8d8f-478003cea319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the secret key\n",
    "# SECRET_KEY = os.getenv()\n",
    "\n",
    "# # Now you can use the SECRET_KEY in your code\n",
    "# print(f'SECRET_KEY:  {SECRET_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3c46a11-5053-493f-b66b-1677555e93f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deps\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d1fea80-0c4b-4bc6-8814-cd56b342fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding PDf local\n",
    "pdf_path = 'transformers.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2588d6ac-cc41-4dcf-9544-8767c6bf6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing PDF\n",
    "if pdf_path:\n",
    "    loader = UnstructuredPDFLoader(file_path = pdf_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c808f420-3456-4076-8b71-a22a1a47d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing Processed pdf\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460adf3f-2161-48cc-92c1-fdc95187a2fa",
   "metadata": {},
   "source": [
    "## Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7719e0d-6410-47cd-8a80-e58169286bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY')\n",
    "# Now you can use the API key to initialize the CohereEmbeddings model\n",
    "embedding_model = CohereEmbeddings(cohere_api_key = COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39c1c07-d15b-40ba-84c7-5d23778d6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecotr embeddings & text spiltter & vecotr store deps\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "67e6e056-fad5-4406-bd57-cb25aa7a50a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting text from pdf and chunking for proper embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ffe016c-70d2-4ab8-be06-db3ab93f01f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a vectorDB\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = embeddings_model,\n",
    "    collection_name = \"rag-pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0de39-fc89-4349-979f-d639d1645052",
   "metadata": {},
   "source": [
    "## Retrievel from VectorDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eab69aa2-1f8e-4af1-8737-d2b7f5d19867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d672ca2c-c74b-4f87-ba46-796379597a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # load groq deps\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ\")\n",
    "# loading the mixtral llm from groq\n",
    "llm = ChatGroq(temperature=0, groq_api_key='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', model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcb78971-c76a-4113-a985-729c3148b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom template saying whenever user input a Query, make 5 alternative similar query\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33a199d3-2825-4487-a384-08a425ccadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing those alternative generated query into vecotor db, this is a custom retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "if not found generate generic answer also along with it mention \"NOT FROM PDF\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "81dc48e4-d0e1-4d83-acc1-fddaae266af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets chain everything\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06ad839c-5ffb-4f99-b83f-a1fcfe218240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Derieve 5 questions from the pdf in points\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. What is the Transformer model and how does it differ from traditional sequence transduction models?\\nAnswer: The Transformer model is a type of sequence transduction model that is based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. This makes it more parallelizable and allows it to significantly reduce training time compared to traditional models.\\n\\n2. How does the Transformer model perform on machine translation tasks?\\nAnswer: The Transformer model has been shown to be superior in quality on two machine translation tasks, achieving a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and a BLEU score of 41.8 on the WMT 2014 English-to-French translation task.\\n\\n3. How does the Transformer model handle long-distance dependencies in sequences?\\nAnswer: The Transformer model handles long-distance dependencies in sequences using self-attention mechanisms, which allow it to attend to all positions in the sequence simultaneously. This allows it to capture dependencies between positions that are far apart in the sequence.\\n\\n4. How does the Transformer model compare to traditional recurrent neural network models in terms of parallelization and training time?\\nAnswer: The Transformer model allows for significantly more parallelization and requires significantly less training time compared to traditional recurrent neural network models.\\n\\n5. What are some of the advantages of using attention mechanisms in sequence transduction models?\\nAnswer: Attention mechanisms allow sequence transduction models to model dependencies without regard to their distance in the input or output sequences. This can improve the quality of the models and make them more parallelizable.\\n\\nNOT FROM PDF:\\n\\n6. How does the Transformer model handle position information in sequences?\\nAnswer: The Transformer model uses positional encoding to inject position information into the sequences it processes. This is necessary because the model does not have an inherent notion of position, as it does not use recurrence or convolutions.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af70e0-a1c9-4cef-bd07-38a876c7345c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convoQuery",
   "language": "python",
   "name": "convoquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

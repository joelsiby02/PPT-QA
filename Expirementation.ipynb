{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173c8bf-fe92-434a-92af-067b384ad600",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"unstructured[all-docs]\"\n",
    "!pip install libmagic-dev poppler-utils tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758eb09-aa03-4b7d-8049-f5d2629a4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the secret key\n",
    "# SECRET_KEY = os.getenv()\n",
    "\n",
    "# # Now you can use the SECRET_KEY in your code\n",
    "# print(f'SECRET_KEY:  {SECRET_KEY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6fff3-4b7b-42cc-83db-0ac72ad0a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deps\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "from langchain_community.document_loaders import OnlinePDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a52e6-b58b-4c47-9abc-4dbee74c2242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laoding PDf local\n",
    "pdf_path = 'transformers.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95a1ba-4e67-4ac9-866e-58052d109cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing PDF\n",
    "if pdf_path:\n",
    "    loader = UnstructuredPDFLoader(file_path = pdf_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF\")\n",
    "\n",
    "\n",
    "# Viewing Processed pdf\n",
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fec6ae-00e9-40b6-adc1-d05740367fff",
   "metadata": {},
   "source": [
    "## Vector Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85374bc-8b8c-4591-bf59-d377edd1e131",
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.getenv('COHERE_API_KEY')\n",
    "# Now you can use the API key to initialize the CohereEmbeddings model\n",
    "embedding_model = CohereEmbeddings(cohere_api_key = COHERE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e47f6-675f-4496-8d95-f1841a18012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vecotr embeddings & text spiltter & vecotr store deps\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8a799-eb58-452a-9d52-50a65a9fe4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting text from pdf and chunking for proper embeddings\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302e2bc-16ba-4ed3-9d9f-9a178e388b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a vectorDB\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = embeddings_model,\n",
    "    collection_name = \"rag-pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff1e3f-0d7c-4157-95c0-960d865dbe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433248e-a65d-4d4f-8c00-9f0b1bf603dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq # load groq deps\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "# loading the mixtral llm from groq\n",
    "llm = ChatGroq(temperature=0, groq_api_key= GROQ_API_KEY, model_name=\"mixtral-8x7b-32768\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87134f5-3443-4cf6-8226-6c4bb6ddcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a custom template saying whenever user input a Query, make 5 alternative similar query\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e333ed-4d64-4361-a334-0fba3c49853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing those alternative generated query into vecotor db, this is a custom retriever\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "if not found generate generic answer also along with it mention \"NOT FROM PDF\"\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a4bda-5186-4e99-90cd-bd41d4a7dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets chain everything\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4944a-90da-4c9a-966c-da5421fda0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.invoke(input(\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convoQuery",
   "language": "python",
   "name": "convoquery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
